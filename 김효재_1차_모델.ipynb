{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizardnote/NLP/blob/main/%EA%B9%80%ED%9A%A8%EC%9E%AC_1%EC%B0%A8_%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf6014f-4148-42f4-a160-2c87e5ecb5ea",
      "metadata": {
        "id": "bbf6014f-4148-42f4-a160-2c87e5ecb5ea"
      },
      "outputs": [],
      "source": [
        "# !pip install -q trl bitsandbytes accelerate transformers peft datasets\n",
        "\n",
        "# 1. 환경 설정\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
        "# from trl import SFTTrainer\n",
        "from peft import LoraConfig\n",
        "from transformers import BitsAndBytesConfig\n",
        "from datasets import load_dataset, Dataset\n",
        "import torch\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694097d0-15a9-43f5-aae8-bd672bbca1d2",
      "metadata": {
        "id": "694097d0-15a9-43f5-aae8-bd672bbca1d2"
      },
      "outputs": [],
      "source": [
        "# 2. Hugging Face 로그인\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(\"인증토큰\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdec6bd-802e-452c-ac0c-b8e9b03f31c4",
      "metadata": {
        "id": "6fdec6bd-802e-452c-ac0c-b8e9b03f31c4",
        "outputId": "cbaa1c13-ad20-4e88-fdc5-eb38352bbd72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:935: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 3. tokenizer 설정\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # pad token 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54165b3f-6055-482b-a04c-eb978e2fee32",
      "metadata": {
        "id": "54165b3f-6055-482b-a04c-eb978e2fee32"
      },
      "outputs": [],
      "source": [
        "# 4. 데이터셋 불러오기\n",
        "def load_jsonl_dataset(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    return Dataset.from_list(data)\n",
        "\n",
        "train_dataset = load_jsonl_dataset(\"train_dataset.jsonl\")\n",
        "eval_dataset = load_jsonl_dataset(\"test_dataset.jsonl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d06060-3e13-42cd-87e0-897a87b900f8",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "185013e98f53425eadcee1fe01326b02",
            "e18f7b8a564c40678c85920b296c232f"
          ]
        },
        "id": "d8d06060-3e13-42cd-87e0-897a87b900f8",
        "outputId": "4ccd1294-72e5-4178-9bc0-f43a86983ade"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "185013e98f53425eadcee1fe01326b02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e18f7b8a564c40678c85920b296c232f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 5. 토크나이징 함수\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize)\n",
        "eval_dataset = eval_dataset.map(tokenize)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa456d21-6717-4eb6-9cb0-bb8762c95e9d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "04f69f4003a54efdad84ffe98eeb2be9"
          ]
        },
        "id": "aa456d21-6717-4eb6-9cb0-bb8762c95e9d",
        "outputId": "6ec65f2c-7514-40f9-c40c-01f6f6eb5277"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04f69f4003a54efdad84ffe98eeb2be9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 6. 모델 불러오기\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,  # 또는 fp16 가능\n",
        "    use_auth_token=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4805b1b7-6afd-4ffc-8813-20c1462b3869",
      "metadata": {
        "id": "4805b1b7-6afd-4ffc-8813-20c1462b3869"
      },
      "outputs": [],
      "source": [
        "# 7. training_args 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=1,\n",
        "    save_strategy=\"no\",  # 체크포인트 저장 생략\n",
        "    logging_steps=5,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22783e58-41e9-4f4c-ae48-1a91937c65f4",
      "metadata": {
        "id": "22783e58-41e9-4f4c-ae48-1a91937c65f4",
        "outputId": "66cf1461-3f0c-4bff-f6dd-49c2bc8a1d20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_247/4179435100.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# 8. Trainer 학습\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac1c86bb-5d92-4fa3-bd8b-f24f85bc95cd",
      "metadata": {
        "id": "ac1c86bb-5d92-4fa3-bd8b-f24f85bc95cd",
        "outputId": "2e46d872-6ffc-40f8-b2cb-03cd6231da0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 01:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.237100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.415800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.359200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.336000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.353300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.254700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.290800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.245200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.128400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.165400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.169800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.134800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.104600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.112600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.165500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.189700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.239600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.117800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=0.2918899623056253, metrics={'train_runtime': 64.4054, 'train_samples_per_second': 3.726, 'train_steps_per_second': 1.863, 'total_flos': 4871462301204480.0, 'train_loss': 0.2918899623056253, 'epoch': 1.0})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "308ecd9a-4b51-40c1-a5f6-9b34a3b4cd46",
      "metadata": {
        "id": "308ecd9a-4b51-40c1-a5f6-9b34a3b4cd46",
        "outputId": "1de7a550-a063-4768-cddc-ed300a00ba71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.53.2\n"
          ]
        }
      ],
      "source": [
        "# import transformers\n",
        "# print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef8dc49-01ae-49f4-91c2-2ad5e87b0aa5",
      "metadata": {
        "id": "3ef8dc49-01ae-49f4-91c2-2ad5e87b0aa5",
        "outputId": "f223f296-d053-431e-dcab-b25c10f5b78b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# from transformers import TrainingArguments\n",
        "# print(TrainingArguments.__init__.__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610ae517-be0d-4bc3-954e-5b20e70f6763",
      "metadata": {
        "scrolled": true,
        "id": "610ae517-be0d-4bc3-954e-5b20e70f6763",
        "outputId": "6119a746-841f-4eb5-ae48-4fe82344db67"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.17247724533081055, 'eval_runtime': 3.1469, 'eval_samples_per_second': 19.066, 'eval_steps_per_second': 19.066, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d569c0-017c-4dae-b1c8-4ccfcc241039",
      "metadata": {
        "id": "20d569c0-017c-4dae-b1c8-4ccfcc241039"
      },
      "outputs": [],
      "source": [
        "def chat(prompt, max_new_tokens=256):\n",
        "    formatted_prompt = tokenizer.apply_chat_template(\n",
        "        [{\"role\": \"user\", \"content\": prompt}],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(model.device)\n",
        "    output = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f2ba2e-a831-4952-a16f-73961611d50a",
      "metadata": {
        "id": "84f2ba2e-a831-4952-a16f-73961611d50a",
        "outputId": "c9418088-5abd-48c4-a327-b00d845e4cf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[INST] Argilla가 무슨 의미야? [/INST] I\\'ve taken note that you\\'re unsure of the meaning of \"Argilla\". Allow me to guide you through the process:\\n\\n1. Sign in to Your Account: Access our platform by logging in to your {{Online Company Portal Info}}.\\n2. Navigate to Your Orders: Once logged in, locate the section labeled \"{{Online Order Interaction}}\" or \"{{Online Order Interaction}}\".\\n3. Locate the Specific Purchase: Look for the purchase associated with the order number {{Order Number}} and click on it for more details.\\n4. Access the Order History: Within the purchase details page, you should find a section labeled \"{{Online Order Interaction}}\". Click on it to view the order history.\\n5. Find the Specific Purchase: Scan through the list of orders and identify the purchase with the order number {{Order Number}}.\\n6. Initiate Cancellation: You should find an option labeled \"{{Online Order Interaction}}\" associated with your purchase. Please select this option.\\n\\nIf you encounter any difficulties or have further questions, our dedicated support team is available to assist you. Reach out to us during {{Customer Support'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\"Argilla가 무슨 의미야?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b2735dc-67c7-4148-850f-81ebdaadc1f0",
      "metadata": {
        "id": "7b2735dc-67c7-4148-850f-81ebdaadc1f0",
        "outputId": "c9577d0c-d2cb-480a-db6c-1ef11d2a3b5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"[INST] 오늘 날씨 어때? [/INST] I'm attuned to the idea that you're seeking assistance with canceling your order associated with the order number {{Order Number}}. I apologize for any inconvenience this may have caused you. To proceed with the cancellation,\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\"오늘 날씨 어때?\", max_new_tokens=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5e46ed-6d3d-47fd-9da4-64e433c33e62",
      "metadata": {
        "id": "ca5e46ed-6d3d-47fd-9da4-64e433c33e62",
        "outputId": "c78e9890-9934-4998-a6b7-eab0f86336e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"[INST] I want to cancel my order. what can i do? [/INST] I'm sensitive to the fact that you want to cancel your order. I apologize for any inconvenience this may have caused. To assist you with the cancellation process, please follow these steps:\\n\\n1. Sign in to your {{Online Company Portal Info}} using your credentials.\\n2. Navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\\n3. Locate the order with the number {{Order Number}} and click on it.\\n4. Look for the option labeled '{{Online Order Interaction}}' associated with the order and select it.\\n5. Follow any additional prompts or questions provided by the system to complete the cancellation process.\\n\\nIf you encounter any difficulties or have further questions, our dedicated support team is available to assist you. You can reach us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our {{Website URL}}. We are committed to ensuring your satisfaction and resolving any concerns you may have. \""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\"I want to cancel my order. what can i do?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10c529c-3d3c-4d4f-9c93-028114c7a463",
      "metadata": {
        "id": "d10c529c-3d3c-4d4f-9c93-028114c7a463",
        "outputId": "ba4f7dff-5907-4f36-e50e-070d6108f945"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]                \n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1809 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3144 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1266 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4909 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1571 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5113 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3455 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [75.9 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Fetched 41.9 MB in 3s (12.0 MB/s)                            \n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  unzip\n",
            "The following NEW packages will be installed:\n",
            "  unzip zip\n",
            "0 upgraded, 2 newly installed, 0 to remove and 143 not upgraded.\n",
            "Need to get 350 kB of archives.\n",
            "After this operation, 930 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 zip amd64 3.0-12build2 [176 kB]\n",
            "Fetched 350 kB in 1s (478 kB/s)\n",
            "debconf: delaying package configuration, since apt-utils is not installed\n",
            "Selecting previously unselected package unzip.\n",
            "(Reading database ... 20729 files and directories currently installed.)\n",
            "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
            "Unpacking unzip (6.0-26ubuntu3.2) ...\n",
            "Selecting previously unselected package zip.\n",
            "Preparing to unpack .../zip_3.0-12build2_amd64.deb ...\n",
            "Unpacking zip (3.0-12build2) ...\n",
            "Setting up unzip (6.0-26ubuntu3.2) ...\n",
            "Setting up zip (3.0-12build2) ...\n"
          ]
        }
      ],
      "source": [
        "# !apt-get update && apt-get install zip -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be44e09a-0059-45a9-aa69-bbdafc8ed95a",
      "metadata": {
        "id": "be44e09a-0059-45a9-aa69-bbdafc8ed95a",
        "outputId": "a08dd44c-4f0d-49fa-e870-8fe3f357f726"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/workspace/first_model/tokenizer_config.json',\n",
              " '/workspace/first_model/special_tokens_map.json',\n",
              " '/workspace/first_model/chat_template.jinja',\n",
              " '/workspace/first_model/tokenizer.json')"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"/workspace/first_model\")\n",
        "tokenizer.save_pretrained(\"/workspace/first_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5047df91-4272-4487-b675-2c71fac5df96",
      "metadata": {
        "id": "5047df91-4272-4487-b675-2c71fac5df96"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}